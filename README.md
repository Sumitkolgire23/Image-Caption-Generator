
---

#      ğŸš€ **Image Caption Generator using Deep Learning**

<p align="center">
  <img src="https://img.shields.io/badge/Deep%20Learning-ResNet50-blue?style=for-the-badge"/>
  <img src="https://img.shields.io/badge/NLP-LSTM-green?style=for-the-badge"/>
  <img src="https://img.shields.io/badge/Framework-TensorFlow-orange?style=for-the-badge"/>
  <img src="https://img.shields.io/badge/Language-Python-yellow?style=for-the-badge"/>
  <img src="https://img.shields.io/badge/Model-Type-Encoder--Decoder-purple?style=for-the-badge"/>
</p>

<p align="center">
  <img src="https://readme-typing-svg.herokuapp.com?size=28&duration=3800&color=00E8FF&center=true&vCenter=true&width=900&lines=ğŸ“¸+Deep+Learning+Model+that+Understands+Images!;ğŸ¤–+Generates+Human-like+Captions+from+Images;ğŸš€+Computer+Vision+%2B+NLP+Hybrid+AI+System;ğŸ”¥+End-to-End+Image+Caption+Generator+Model"/>
</p>

---

# ğŸŒŒ **About the Project**

This project is a **complete pipeline** that allows AI to *see an image and describe it in English*.
It combines **Convolutional Neural Networks (CNN)** for vision and **LSTM networks** for language modeling.

âœ¨ The model understands scenes, objects, and their relationships â€” and transforms them into meaningful sentences.

---

# ğŸ§  **System Architecture**

<p align="center">
  <img src="images/systemdiagram.PNG" width="80%" />
</p>

---

# ğŸ”§ **Processing Pipeline**

```
ğŸ–¼ Image â†’ ğŸ” ResNet50 Feature Extractor â†’ ğŸ“ 2048-d Vector
        â†“
ğŸ“ Caption Preprocessing (tokenization, cleaning, start/end tokens)
        â†“
ğŸ§  LSTM Decoder learns to predict next words
        â†“
ğŸ¯ Greedy Search generates final caption
```

---

# ğŸ—„ **Dataset Details**

* **Dataset Used:** Flickr30K
* **Images:** 31,783
* **Captions per Image:** 5
* **Training Process Includes:**

  * Lowercasing
  * Removing non-alphabetic characters
  * Sequence padding
  * Mapping words to indices
  * Vocabulary creation

---

# âœ¨ **Key Features**

| Feature                         | Description                                                   |
| ------------------------------- | ------------------------------------------------------------- |
| ğŸ” **Image Feature Extraction** | ResNet50 pretrained on ImageNet extracts deep visual features |
| âœ¨ **Text Preprocessing**        | Cleans captions & prepares vocabulary dictionaries            |
| ğŸ§  **Encoder-Decoder Model**    | Vision encoder + LSTM decoder                                 |
| ğŸ¯ **Greedy Search**            | Selects highest probability words                             |
| ğŸ§ª **BLEU Score**               | Measures caption quality                                      |
| ğŸ–¥ **Tkinter GUI**              | Upload an image â†’ get instant caption                         |

---

# ğŸ’¡ **Advanced Details Added**

### ğŸ§© Vocabulary Construction

* Creates `word_to_index` and `index_to_word` mappings
* Filters rare words
* Handles unknown tokens

### ğŸ‹ï¸ Training Behavior

* Trains in batches using a **generator function**
* Uses parallel sequences of image features + partial captions
* Uses **categorical cross-entropy** loss

### ğŸ“Š Evaluation

* BLEU-1, BLEU-2 scores
* Testing on unseen images
* Visualization of captions

---

# ğŸ›  **Tech Stack**

<p align="center">
  <img src="https://skillicons.dev/icons?i=python,tensorflow,keras,git,anaconda" />
</p>

---

# ğŸ“¦ **Installation**

```bash
git clone https://github.com/yourusername/image-caption-generator.git
cd image-caption-generator
pip install -r requirements.txt
```

---

# ğŸ§¹ **Data Cleaning Example**

```python
def clean(text):
    text = text.lower()
    text = re.sub("[^a-z]+", " ", text)
    return text
```

---

# ğŸ— **Training the Model**

### Step 1 â€” Text Preprocessing

```
run text_data_processing.ipynb
```

### Step 2 â€” Train CNN+LSTM Model

```
run model_build.ipynb
```

### Step 3 â€” Live Caption Testing

```
python ui.py
```

---

# ğŸ† **Model Results**

<p align="center">
  <img src="images/caption3.JPG" width="45%" />
  <img src="images/caption4.JPG" width="45%" />
</p>

---

# ğŸ–¼ **Interactive Desktop UI**

<p align="center">
  <img src="images/ui.JPG" width="70%"/>
</p>

---

# ğŸ“ **Project Structure**

```
ğŸ“¦ Image Caption Generator
 â”£ ğŸ“‚ data
 â”ƒ â”£ ğŸ“‚ Images
 â”ƒ â”— ğŸ“‚ textFiles
 â”£ ğŸ“‚ model_checkpoints
 â”£ ğŸ“‚ images
 â”£ ğŸ“œ text_data_processing.ipynb
 â”£ ğŸ“œ model_build.ipynb
 â”£ ğŸ“œ ui.py
 â”£ ğŸ“œ README.md
 â”— ğŸ“œ requirements.txt
```

---

# ğŸ **How it Works â€” Summary**

* Image â†’ ResNet50 â†’ feature vector
* Caption â†’ integer tokens
* LSTM predicts next words
* Decoder + Greedy Search â†’ final output sentence

---

# ğŸ”¥ **Animated Hero Banner**

<p align="center">
  <img src="https://readme-typing-svg.herokuapp.com?size=25&duration=3500&color=FF6AE6&center=true&vCenter=true&width=700&lines=AI+that+Describes+the+World.;From+Pixels+to+Words.;Image+Captioning+Made+Simple.;Powered+by+Deep+Learning."/>
</p>

---

# ğŸ‘¤ **Author**

### **Sumit Kolgire (Shadow)**

AI/ML Engineer | Deep Learning | NLP | Computer Vision
ğŸ”— LinkedIn: [https://www.linkedin.com/in/sumit-kolgire](https://www.linkedin.com/in/sumit-kolgire)

---

# â­ **Support the Project**

If this project helped you, consider giving it a **â­ on GitHub** to support future work!

---
