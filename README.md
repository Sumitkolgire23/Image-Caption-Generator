
---

# ğŸš€ **Image Caption Generator using Deep Learning**

<p align="center">
  <img src="https://img.shields.io/badge/Deep%20Learning-ResNet50-blue?style=for-the-badge"/>
  <img src="https://img.shields.io/badge/NLP-LSTM-green?style=for-the-badge"/>
  <img src="https://img.shields.io/badge/Framework-TensorFlow-orange?style=for-the-badge"/>
  <img src="https://img.shields.io/badge/Language-Python-yellow?style=for-the-badge"/>
</p>

<p align="center">
  <img src="https://readme-typing-svg.herokuapp.com?size=28&duration=4000&color=00F7FF&center=true&vCenter=true&width=900&lines=ğŸ“¸+AI+that+Understands+Images+and+Describes+Them!;ğŸ¤–+Combining+Computer+Vision+%2B+NLP+to+Generate+Captions;ğŸš€+Deep+Learning+based+End-to-End+Image+Captioning+System" />
</p>

---

## ğŸŒŸ **Project Overview**

This project automatically **generates English captions** for input images using:

* **ResNet50** for feature extraction
* **LSTM-based Encoderâ€“Decoder** for caption generation
* **Flickr30k Dataset** for training
* **Greedy Search** for inference

The system combines **Computer Vision** + **Natural Language Processing** to make machines *describe* what they see.

---

## ğŸ§  **Architecture**

<p align="center">
  <img src="https://github.com/yourusername/yourrepo/raw/main/images/systemdiagram.png" width="80%" />
</p>

### ğŸ”§ Workflow

```
Input Image â†’ ResNet50 â†’ Feature Vector (2048-d)
                         â†“
                  LSTM Decoder
                         â†“
                Generated Caption
```

---

## ğŸ“‚ **Dataset Info**

âœ” Flickr30k Dataset (30,000 images)
âœ” Each image contains **5 human-written captions**
âœ” Captions cleaned + tokenized
âœ” Special tokens added: `<start>` and `<end>`

---

# âœ¨ **Features**

| Feature                         | Description                                   |
| ------------------------------- | --------------------------------------------- |
| ğŸ” **Image Feature Extraction** | ResNet50 pretrained on ImageNet               |
| âœï¸ **Caption Preprocessing**    | Cleaning, lowercasing, removing special chars |
| ğŸ§  **Sequence Modeling**        | LSTM model trained to predict next word       |
| ğŸš€ **Inference**                | Greedy Search for final caption               |
| ğŸ§ª **Evaluation**               | BLEU Score                                    |
| ğŸ–¥ï¸ **Desktop UI**              | Full Tkinter-based testing interface          |

---

## ğŸ›  **Tech Stack**

<p align="center">
  <img src="https://skillicons.dev/icons?i=python,tensorflow,anaconda,git" />
</p>

---

# ğŸ“¦ **Installation**

```bash
git clone https://github.com/yourusername/image-caption-generator.git
cd image-caption-generator
pip install -r requirements.txt
```

---

# ğŸ§¹ **Data Cleaning Example**

```python
def clean(text):
    text = text.lower()
    text = re.sub("[^a-z]+", " ", text)
    return text
```

---

# ğŸ— **Model Training**

### **Step 1 â€” Preprocess Text**

```
run text_data_processing.ipynb
```

### **Step 2 â€” Train the Model**

```
run model_build.ipynb
```

### **Step 3 â€” Test with UI**

```
python ui.py
```

---

# ğŸ”¥ **Results**

### ğŸ–¼ Example Output

<p align="center">
  <img src="https://github.com/yourusername/yourrepo/raw/main/images/caption3.JPG" width="45%" />
  <img src="https://github.com/yourusername/yourrepo/raw/main/images/caption4.JPG" width="45%" />
</p>

---

# ğŸ–¼ **Live Captioning UI**

<p align="center">
  <img src="https://github.com/yourusername/yourrepo/raw/main/images/ui.JPG" width="70%"/>
</p>

---

# ğŸ“ **Project Structure**

```
ğŸ“¦ Image Caption Generator
 â”£ ğŸ“‚ data
 â”ƒ â”£ ğŸ“‚ Images
 â”ƒ â”— ğŸ“‚ textFiles
 â”£ ğŸ“‚ model_checkpoints
 â”£ ğŸ“‚ images
 â”£ ğŸ“œ text_data_processing.ipynb
 â”£ ğŸ“œ model_build.ipynb
 â”£ ğŸ“œ ui.py
 â”£ ğŸ“œ README.md
 â”— ğŸ“œ requirements.txt
```

---

# ğŸ **How the System Works (Summary)**

1. Image sent through **ResNet50 CNN**
2. Last layer removed â†’ produces **2048-dimension vector**
3. Vector + caption tokens passed to LSTM
4. LSTM predicts next word probabilities
5. Highest probability word selected (Greedy Search)
6. Final caption generated

---

# ğŸ§ª **BLEU Evaluation**

BLEU score is used to measure similarity between generated and real captions.

---

# ğŸ§‘â€ğŸ’» **Author**

### ğŸ‘¤ *Sumit Kolgire (Shadow)*

ğŸš€ AI/ML Engineer | Deep Learning | NLP | Computer Vision
ğŸ”— [LinkedIn](https://www.linkedin.com/in/sumit-kolgire)

---

# â­ **Support**

If you like this project, give it a **star â­ on GitHub** â€” it motivates further development!

---


